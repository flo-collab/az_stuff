{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.45.0\n",
      "Pipeline SDK-specific imports completed\n",
      "Preparation-AI102-Florian\n",
      "cloud-shell-storage-westeurope\n",
      "westeurope\n",
      "0252a218-2d27-4d77-a4f1-b638272c95e0\n",
      "Blobstore's name: workspaceblobstore\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore, Experiment, Dataset\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "print(\"Pipeline SDK-specific imports completed\")\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
    "\n",
    "# Default datastore (Azure blob storage)\n",
    "# def_blob_store = ws.get_default_datastore()\n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "print(\"Blobstore's name: {}\".format(def_blob_store.name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aml_compute_target = \"cpu-cluster\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"creating new compute target\")\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1, \n",
    "                                                                max_nodes = 1)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a public dataset path\n",
    "data_path = \"https://dprepdata.blob.core.windows.net/demo/Titanic.csv\"\n",
    "# Or uploading data to the datastore\n",
    "# data_path = def_blob_store.upload_files([\"./your_data.pkl\"], target_path=\"your_path\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "# Reference the data uploaded to blob storage using file dataset\n",
    "# Assign the datasource to blob_input_data variable\n",
    "blob_input_data = Dataset.File.from_files(data_path).as_named_input(\"test_data\")\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dataset object created\n"
     ]
    }
   ],
   "source": [
    "# Define intermediate data using OutputFileDatasetConfig\n",
    "processed_data1 = OutputFileDatasetConfig(name=\"processed_data1\")\n",
    "print(\"Output dataset object created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainStep created\n"
     ]
    }
   ],
   "source": [
    "# trainStep consumes the datasource (Datareference) in the previous step\n",
    "# and produces processed_data1\n",
    "\n",
    "source_directory = \"publish_run_train\"\n",
    "\n",
    "trainStep = PythonScriptStep(\n",
    "    script_name=\"train.py\", \n",
    "        arguments=[\"--input_data\", blob_input_data.as_mount(), \"--output_train\", processed_data1],\n",
    "    compute_target=aml_compute, \n",
    "    source_directory=source_directory\n",
    ")\n",
    "print(\"trainStep created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extractStep created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# extractStep to use the intermediate data produced by trainStep\n",
    "# This step also produces an output processed_data2\n",
    "processed_data2 = OutputFileDatasetConfig(name=\"processed_data2\")\n",
    "source_directory = \"publish_run_extract\"\n",
    "\n",
    "extractStep = PythonScriptStep(\n",
    "    script_name=\"extract.py\",\n",
    "    arguments=[\"--input_extract\", processed_data1.as_input(), \"--output_extract\", processed_data2],\n",
    "    compute_target=aml_compute, \n",
    "    source_directory=source_directory)\n",
    "print(\"extractStep created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline parameter created\n"
     ]
    }
   ],
   "source": [
    "# We will use this later in publishing pipeline\n",
    "pipeline_param = PipelineParameter(name=\"pipeline_arg\", default_value=10)\n",
    "print(\"pipeline parameter created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compareStep created\n"
     ]
    }
   ],
   "source": [
    "# Now define compareStep that takes two inputs (both intermediate data), and produce an output\n",
    "processed_data3 = OutputFileDatasetConfig(name=\"processed_data3\")\n",
    "\n",
    "# You can register the output as dataset after job completion\n",
    "processed_data3 = processed_data3.register_on_complete(\"compare_result\")\n",
    "\n",
    "source_directory = \"publish_run_compare\"\n",
    "\n",
    "compareStep = PythonScriptStep(\n",
    "    script_name=\"compare.py\",\n",
    "    arguments=[\"--compare_data1\", processed_data1.as_input(), \"--compare_data2\", processed_data2.as_input(), \"--output_compare\", processed_data3, \"--pipeline_param\", pipeline_param],  \n",
    "    compute_target=aml_compute, \n",
    "    source_directory=source_directory)\n",
    "print(\"compareStep created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Step [compare.py]: script not found at: c:\\Users\\fuetu\\gitlocal\\DP100\\mslearn-dp100\\publish_run_compare\\compare.py. Make sure to specify an appropriate source_directory on the Step or default_source_directory on the Pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pipeline1 \u001b[38;5;241m=\u001b[39m Pipeline(workspace\u001b[38;5;241m=\u001b[39mws, steps\u001b[38;5;241m=\u001b[39m[compareStep])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline is built\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\core\\_experiment_method.py:104\u001b[0m, in \u001b[0;36mexperiment_method.<locals>.real_decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[39m:param init_func:\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39m:type init_func: object\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39m:rtype: object\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    103\u001b[0m ExperimentSubmitRegistrar\u001b[39m.\u001b[39mregister_submit_function(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, submit_function)\n\u001b[1;32m--> 104\u001b[0m \u001b[39mreturn\u001b[39;00m init_func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\core\\pipeline.py:180\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, workspace, steps, description, default_datastore, default_source_directory, resolve_closure, _workflow_provider, _service_endpoint, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mparameter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not recognized for Pipeline \u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m key)\n\u001b[0;32m    179\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_email_notification \u001b[39m=\u001b[39m enable_email_notification\n\u001b[1;32m--> 180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph_builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, steps, finalize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py:1497\u001b[0m, in \u001b[0;36m_PipelineGraphBuilder.build\u001b[1;34m(self, name, steps, finalize, regenerate_outputs)\u001b[0m\n\u001b[0;32m   1493\u001b[0m     \u001b[39mexcept\u001b[39;00m HttpOperationError:\n\u001b[0;32m   1494\u001b[0m         \u001b[39m# If the workspace does not have a default datastore, keep default_datastore unset\u001b[39;00m\n\u001b[0;32m   1495\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m-> 1497\u001b[0m graph \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct(name, steps)\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m finalize:\n\u001b[0;32m   1499\u001b[0m     graph\u001b[39m.\u001b[39mfinalize(regenerate_outputs\u001b[39m=\u001b[39mregenerate_outputs)\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py:1519\u001b[0m, in \u001b[0;36m_PipelineGraphBuilder.construct\u001b[1;34m(self, name, steps)\u001b[0m\n\u001b[0;32m   1517\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph \u001b[39m=\u001b[39m Graph(name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context)\n\u001b[0;32m   1518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodeStack\u001b[39m.\u001b[39mappend([])\n\u001b[1;32m-> 1519\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_collection(steps)\n\u001b[0;32m   1520\u001b[0m \u001b[39mfor\u001b[39;00m builder \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_builderStack[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[0;32m   1521\u001b[0m     builder\u001b[39m.\u001b[39mapply_rules()\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py:1555\u001b[0m, in \u001b[0;36m_PipelineGraphBuilder.process_collection\u001b[1;34m(self, collection)\u001b[0m\n\u001b[0;32m   1553\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodeStack\u001b[39m.\u001b[39mappend([])\n\u001b[0;32m   1554\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_builderStack\u001b[39m.\u001b[39mappend(builder)\n\u001b[1;32m-> 1555\u001b[0m builder\u001b[39m.\u001b[39;49mprocess_collection(collection)\n\u001b[0;32m   1556\u001b[0m added_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodeStack\u001b[39m.\u001b[39mpop()\n\u001b[0;32m   1557\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodeStack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mextend(added_nodes)\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py:1846\u001b[0m, in \u001b[0;36m_ParallelPipelineGraphBuilder.process_collection\u001b[1;34m(self, collection)\u001b[0m\n\u001b[0;32m   1839\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1840\u001b[0m \u001b[39mProcess collection.\u001b[39;00m\n\u001b[0;32m   1841\u001b[0m \n\u001b[0;32m   1842\u001b[0m \u001b[39m:param collection: The collection of nodes.\u001b[39;00m\n\u001b[0;32m   1843\u001b[0m \u001b[39m:type collection: builtin.list\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1845\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m collection:\n\u001b[1;32m-> 1846\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_base_builder\u001b[39m.\u001b[39;49mprocess_collection(item)\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py:1549\u001b[0m, in \u001b[0;36m_PipelineGraphBuilder.process_collection\u001b[1;34m(self, collection)\u001b[0m\n\u001b[0;32m   1547\u001b[0m \u001b[39m# just a step?\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(collection, PipelineStep):\n\u001b[1;32m-> 1549\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_step(collection)\n\u001b[0;32m   1551\u001b[0m \u001b[39m# delegate to correct builder\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m builder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_builder(collection)\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py:1593\u001b[0m, in \u001b[0;36m_PipelineGraphBuilder.process_step\u001b[1;34m(self, step)\u001b[0m\n\u001b[0;32m   1590\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step2node:\n\u001b[0;32m   1591\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step2node[step]\n\u001b[1;32m-> 1593\u001b[0m node \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49mcreate_node(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_datastore, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context)\n\u001b[0;32m   1594\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massert_node_valid(step, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph, node)\n\u001b[0;32m   1596\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step2node[step] \u001b[39m=\u001b[39m node\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\steps\\python_script_step.py:243\u001b[0m, in \u001b[0;36mPythonScriptStep.create_node\u001b[1;34m(self, graph, default_datastore, context)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_node\u001b[39m(\u001b[39mself\u001b[39m, graph, default_datastore, context):\n\u001b[0;32m    225\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[39m    Create a node for PythonScriptStep and add it to the specified graph.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39m    :rtype: azureml.pipeline.core.graph.Node\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(PythonScriptStep, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mcreate_node(\n\u001b[0;32m    244\u001b[0m         graph\u001b[39m=\u001b[39;49mgraph, default_datastore\u001b[39m=\u001b[39;49mdefault_datastore, context\u001b[39m=\u001b[39;49mcontext)\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\core\\_python_script_step_base.py:104\u001b[0m, in \u001b[0;36m_PythonScriptStepBase.create_node\u001b[1;34m(self, graph, default_datastore, context)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39mCreate a node for python script step.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39m:rtype: azureml.pipeline.core.graph.Node\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_command:\n\u001b[1;32m--> 104\u001b[0m     source_directory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_source_directory(context, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_source_directory, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_script_name)\n\u001b[0;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     source_directory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_source_directory\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py:1049\u001b[0m, in \u001b[0;36mPipelineStep.get_source_directory\u001b[1;34m(self, context, source_directory, script_name)\u001b[0m\n\u001b[0;32m   1046\u001b[0m     source_directory \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mdefault_source_directory\n\u001b[0;32m   1048\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodule\u001b[39;00m \u001b[39mimport\u001b[39;00m Module\n\u001b[1;32m-> 1049\u001b[0m \u001b[39mreturn\u001b[39;00m Module\u001b[39m.\u001b[39;49mprocess_source_directory(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, source_directory, script_name)\n",
      "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\pipeline\\core\\module.py:232\u001b[0m, in \u001b[0;36mModule.process_source_directory\u001b[1;34m(name, source_directory, script_name)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(script_path):\n\u001b[0;32m    231\u001b[0m     abs_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(script_path)\n\u001b[1;32m--> 232\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mStep [\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m]: script not found at: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Make sure to specify an appropriate \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39msource_directory on the Step or default_source_directory on the Pipeline.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m                      \u001b[39m%\u001b[39m (name, abs_path))\n\u001b[0;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m source_directory\n",
      "\u001b[1;31mValueError\u001b[0m: Step [compare.py]: script not found at: c:\\Users\\fuetu\\gitlocal\\DP100\\mslearn-dp100\\publish_run_compare\\compare.py. Make sure to specify an appropriate source_directory on the Step or default_source_directory on the Pipeline."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pipeline1 = Pipeline(workspace=ws, steps=[compareStep])\n",
    "print (\"Pipeline is built\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DP100-IdpZmbhO')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6be20d35a0fe9891e9592b51856519ffefec3add89e5783bfb8eccfc4b79debb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
