{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a real-time inferencing service\n",
        "\n",
        "After training a predictive model, you can deploy it as a real-time service that clients can use to get predictions from new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1649367571437
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready to use Azure ML 1.45.0 to work with Preparation-AI102-Florian\n"
          ]
        }
      ],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train and register a model\n",
        "\n",
        "Now let's train and register a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1649367606601
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting experiment: mslearn-train-diabetes\n",
            "Loading Data...\n",
            "Training a decision tree model\n",
            "Accuracy: 0.894\n",
            "AUC: 0.88255634608687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\fuetu\\AppData\\Local\\Temp\\ipykernel_3912\\3157788198.py:34: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  run.log('Accuracy', np.float(acc))\n",
            "C:\\Users\\fuetu\\AppData\\Local\\Temp\\ipykernel_3912\\3157788198.py:40: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  run.log('AUC', np.float(auc))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model trained and registered.\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.core import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace=ws, name=\"mslearn-train-diabetes\")\n",
        "run = experiment.start_logging()\n",
        "print(\"Starting experiment:\", experiment.name)\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = pd.read_csv('data/diabetes.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a decision tree model\n",
        "print('Training a decision tree model')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the trained model\n",
        "model_file = 'diabetes_model.pkl'\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
        "\n",
        "# Complete the run\n",
        "run.complete()\n",
        "\n",
        "# Register the model\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model_lala',\n",
        "                   tags={'Training context':'Inline Training'},\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "print('Model trained and registered.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy the model as a web service\n",
        "\n",
        "You have trained and registered a machine learning model that classifies patients based on the likelihood of them having diabetes. This model could be used in a production environment such as a doctor's surgery where only patients deemed to be at risk need to be subjected to a clinical test for diabetes. To support this scenario, you will deploy the model as a web service.\n",
        "\n",
        "First, let's determine what models you have registered in the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "diabetes_model_lala version: 1\n",
            "\t Training context : Inline Training\n",
            "\t AUC : 0.88255634608687\n",
            "\t Accuracy : 0.894\n",
            "\n",
            "\n",
            "diabetes_model version: 8\n",
            "\t Training context : Inline Training\n",
            "\t AUC : 0.8746131648340713\n",
            "\t Accuracy : 0.8876666666666667\n",
            "\n",
            "\n",
            "diabetes_model version: 7\n",
            "\t Training context : Pipeline\n",
            "\t AUC : 0.8825987589818095\n",
            "\t Accuracy : 0.8977777777777778\n",
            "\n",
            "\n",
            "diabetes_model version: 6\n",
            "\t Training context : Pipeline\n",
            "\t AUC : 0.8831011032550847\n",
            "\t Accuracy : 0.8984444444444445\n",
            "\n",
            "\n",
            "diabetes_model version: 5\n",
            "\t Training context : File dataset\n",
            "\t AUC : 0.8568517900798176\n",
            "\t Accuracy : 0.7891111111111111\n",
            "\n",
            "\n",
            "diabetes_model version: 4\n",
            "\t Training context : Tabular dataset\n",
            "\t AUC : 0.8568650620553335\n",
            "\t Accuracy : 0.7893333333333333\n",
            "\n",
            "\n",
            "diabetes_model version: 3\n",
            "\t Training context : Parameterized script\n",
            "\t AUC : 0.8482307577491418\n",
            "\t Accuracy : 0.7743333333333333\n",
            "\n",
            "\n",
            "diabetes_model version: 2\n",
            "\t Training context : Parameterized script\n",
            "\t AUC : 0.8484377332205582\n",
            "\t Accuracy : 0.774\n",
            "\n",
            "\n",
            "diabetes_model version: 1\n",
            "\t Training context : Script\n",
            "\t AUC : 0.8483441962286681\n",
            "\t Accuracy : 0.774\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Right, now let's get the model that we want to deploy. By default, if we specify a model name, the latest version will be returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "diabetes_model_lala version 1\n"
          ]
        }
      ],
      "source": [
        "model = ws.models['diabetes_model_lala']\n",
        "print(model.name, 'version', model.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'diabetes_model': Model(workspace=Workspace.create(name='Preparation-AI102-Florian', subscription_id='0252a218-2d27-4d77-a4f1-b638272c95e0', resource_group='cloud-shell-storage-westeurope'), name=diabetes_model, id=diabetes_model:8, version=8, tags={'Training context': 'Inline Training'}, properties={'AUC': '0.8746131648340713', 'Accuracy': '0.8876666666666667'})}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ws.models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We're going to create a web service to host this model, and this will require some code and configuration files; so let's create a folder for those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./diabetes_service folder created.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the deployment files\n",
        "deployment_folder = './diabetes_service'\n",
        "os.makedirs(deployment_folder, exist_ok=True)\n",
        "print(deployment_folder, 'folder created.')\n",
        "\n",
        "# Set path for scoring script\n",
        "script_file = 'score_diabetes.py'\n",
        "script_path = os.path.join(deployment_folder,script_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The web service where we deploy the model will need some Python code to load the input data, get the model from the workspace, and generate and return predictions. We'll save this code in an *entry script* (often called a *scoring script*) that will be deployed to the web service.\n",
        "\n",
        "The script consists of two functions:\n",
        "\n",
        "- **init**: This function is called when the service is initialized, and is generally used to load the model. Note that the scoring script uses the **AZUREML_MODEL_DIR** environment variable to determine the folder where the model is stored.\n",
        "- **run**: This function is called each time a client application submits new data, and is generally used to inference predictions from the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./diabetes_service\\score_diabetes.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_path\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Called when the service is loaded\n",
        "def init():\n",
        "    global model\n",
        "    # Get the path to the deployed model file and load it\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\n",
        "    print(os.listdir(os.getenv('AZUREML_MODEL_DIR')))\n",
        "    # model_path = os.path.join('outputs/', 'diabetes_model.pkl')\n",
        "    \n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "# Called when a request is received\n",
        "def run(raw_data):\n",
        "    # Get the input data as a numpy array\n",
        "    data = np.array(json.loads(raw_data)['data'])\n",
        "    # Get a prediction from the model\n",
        "    predictions = model.predict(data)\n",
        "    # Get the corresponding classname for each prediction (0 or 1)\n",
        "    classnames = ['not-diabetic', 'diabetic']\n",
        "    predicted_classes = []\n",
        "    for prediction in predictions:\n",
        "        predicted_classes.append(classnames[prediction])\n",
        "    # Return the predictions as JSON\n",
        "    return json.dumps(predicted_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The web service will be hosted in a container, and the container will need to install any required Python dependencies when it gets initialized. In this case, our scoring code requires **scikit-learn** and some Azure Machine Learning specific packages that are used by the scoring web service, so we'll create an environment that included these. Then we'll add that environment to an *inference configuration* along with the scoring script, and define a *deployment configuration* for the container in which the environment and script will be hosted.\n",
        "\n",
        "We can then deploy the model as a service based on these configurations.\n",
        "\n",
        "> **More Information**: For more details about model deployment, and options for target execution environments, see the [documentation](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where).\n",
        "\n",
        "Deployment will take some time as it first runs a process to create a container image, and then runs a process to create a web service based on the image. When deployment has completed successfully, you'll see a status of **Healthy**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deploying model...\n",
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-09-27 22:13:15+02:00 Creating Container Registry if not exists.\n",
            "2022-09-27 22:13:16+02:00 Registering the environment.\n",
            "2022-09-27 22:13:16+02:00 Use the existing image.\n",
            "2022-09-27 22:13:16+02:00 Generating deployment configuration.\n",
            "2022-09-27 22:13:17+02:00 Submitting deployment to compute.\n",
            "2022-09-27 22:13:23+02:00 Checking the status of deployment diabetes-service4..\n",
            "2022-09-27 22:14:45+02:00 Checking the status of inference endpoint diabetes-service4.\n",
            "Failed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
            "Operation ID: b40438a8-3372-4589-8dd6-49247c6908ac\n",
            "More information can be found using '.get_logs()'\n",
            "Error:\n",
            "{\n",
            "  \"code\": \"AciDeploymentFailed\",\n",
            "  \"statusCode\": 400,\n",
            "  \"message\": \"Aci Deployment failed with exception: Error in entry script, KeyError: 0, please run print(service.get_logs()) to get details.\",\n",
            "  \"details\": [\n",
            "    {\n",
            "      \"code\": \"CrashLoopBackOff\",\n",
            "      \"message\": \"Error in entry script, KeyError: 0, please run print(service.get_logs()) to get details.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        },
        {
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: b40438a8-3372-4589-8dd6-49247c6908ac\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Error in entry script, KeyError: 0, please run print(service.get_logs()) to get details.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, KeyError: 0, please run print(service.get_logs()) to get details.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: b40438a8-3372-4589-8dd6-49247c6908ac\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Error in entry script, KeyError: 0, please run print(service.get_logs()) to get details.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, KeyError: 0, please run print(service.get_logs()) to get details.\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [37], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m service_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiabetes-service4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m service \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mdeploy(ws, service_name, [model], inference_config, deployment_config, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 20\u001b[0m service\u001b[38;5;241m.\u001b[39mwait_for_deployment(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(service\u001b[38;5;241m.\u001b[39mstate)\n",
            "File \u001b[1;32mc:\\Users\\fuetu\\.virtualenvs\\DP100-IdpZmbhO\\lib\\site-packages\\azureml\\core\\webservice\\webservice.py:918\u001b[0m, in \u001b[0;36mWebservice.wait_for_deployment\u001b[1;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m logs_response:\n\u001b[0;32m    916\u001b[0m             logs_response \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCurrent sub-operation type not known, more logs unavailable.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 918\u001b[0m         \u001b[39mraise\u001b[39;00m WebserviceException(\u001b[39m'\u001b[39m\u001b[39mService deployment polling reached non-successful terminal state, current \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    919\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mservice state: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    920\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mOperation ID: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    921\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    922\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mError:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    923\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operation_endpoint\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[0;32m    924\u001b[0m                                               logs_response, format_error_response), logger\u001b[39m=\u001b[39mmodule_logger)\n\u001b[0;32m    925\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m service creation operation finished, operation \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_webservice_type,\n\u001b[0;32m    926\u001b[0m                                                                           operation_state))\n\u001b[0;32m    927\u001b[0m \u001b[39mexcept\u001b[39;00m WebserviceException \u001b[39mas\u001b[39;00m e:\n",
            "\u001b[1;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: b40438a8-3372-4589-8dd6-49247c6908ac\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Error in entry script, KeyError: 0, please run print(service.get_logs()) to get details.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, KeyError: 0, please run print(service.get_logs()) to get details.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: b40438a8-3372-4589-8dd6-49247c6908ac\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Error in entry script, KeyError: 0, please run print(service.get_logs()) to get details.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, KeyError: 0, please run print(service.get_logs()) to get details.\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "# Configure the scoring environment\n",
        "service_env = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\")\n",
        "service_env.inferencing_stack_version=\"latest\"\n",
        "\n",
        "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
        "                                   entry_script=script_file,\n",
        "                                   environment=service_env)\n",
        "\n",
        "# Configure the web service container\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "# Deploy the model as a service\n",
        "print('Deploying model...')\n",
        "service_name = \"diabetes-service4\"\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
        "service.wait_for_deployment(True)\n",
        "print(service.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hopefully, the deployment has been successful and you can see a status of **Healthy**. If not, you can use the following code to get the service logs to help you troubleshoot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-27T20:15:27,275569179+00:00 - rsyslog/run \n",
            "2022-09-27T20:15:27,282734836+00:00 - gunicorn/run \n",
            "2022-09-27T20:15:27,293811223+00:00 - nginx/run \n",
            "2022-09-27T20:15:27,303531399+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:27,325203869+00:00 | gunicorn/run | ###############################################\n",
            "2022-09-27T20:15:27,336047755+00:00 | gunicorn/run | AzureML Container Runtime Information\n",
            "2022-09-27T20:15:27,339902685+00:00 | gunicorn/run | ###############################################\n",
            "2022-09-27T20:15:27,346822039+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:27,350920672+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:27,364513578+00:00 | gunicorn/run | AzureML image information: sklearn-0.24.1-ubuntu18.04-py37-cpu-inference:20220516.v10\n",
            "2022-09-27T20:15:27,368341008+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:27,373381348+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:27,378044785+00:00 | gunicorn/run | PATH environment variable: /opt/miniconda/envs/amlenv/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
            "2022-09-27T20:15:27,380929807+00:00 | gunicorn/run | PYTHONPATH environment variable: \n",
            "2022-09-27T20:15:27,382379919+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:27,384561936+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n",
            "\n",
            "azure-core==1.24.0\n",
            "azure-identity==1.10.0\n",
            "azureml-inference-server-http==0.6.1\n",
            "cachetools==5.1.0\n",
            "certifi==2021.10.8\n",
            "cffi==1.15.0\n",
            "charset-normalizer==2.0.12\n",
            "click==7.1.2\n",
            "cryptography==37.0.2\n",
            "Flask==1.0.3\n",
            "google-api-core==2.7.3\n",
            "google-auth==2.6.6\n",
            "googleapis-common-protos==1.56.1\n",
            "gunicorn==20.1.0\n",
            "idna==3.3\n",
            "inference-schema==1.4.1\n",
            "itsdangerous==1.1.0\n",
            "Jinja2==3.0.3\n",
            "joblib==1.1.0\n",
            "MarkupSafe==2.1.1\n",
            "msal==1.17.0\n",
            "msal-extensions==1.0.0\n",
            "numpy==1.21.6\n",
            "opencensus==0.9.0\n",
            "opencensus-context==0.1.2\n",
            "opencensus-ext-azure==1.1.4\n",
            "pandas==1.1.5\n",
            "portalocker==2.4.0\n",
            "protobuf==3.20.1\n",
            "psutil==5.9.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycparser==2.21\n",
            "PyJWT==2.4.0\n",
            "python-dateutil==2.8.2\n",
            "pytz==2022.1\n",
            "requests==2.27.1\n",
            "rsa==4.8\n",
            "scikit-learn==0.24.1\n",
            "scipy==1.7.3\n",
            "six==1.16.0\n",
            "threadpoolctl==3.1.0\n",
            "typing-extensions==4.2.0\n",
            "urllib3==1.26.9\n",
            "Werkzeug==1.0.1\n",
            "wrapt==1.12.1\n",
            "\n",
            "2022-09-27T20:15:30,320313432+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:30,327893849+00:00 | gunicorn/run | Entry script directory: /var/azureml-app\n",
            "2022-09-27T20:15:30,330540855+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:30,335883467+00:00 | gunicorn/run | ###############################################\n",
            "2022-09-27T20:15:30,339824876+00:00 | gunicorn/run | Dynamic Python Package Installation\n",
            "2022-09-27T20:15:30,344562287+00:00 | gunicorn/run | ###############################################\n",
            "2022-09-27T20:15:30,347097692+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:30,353732907+00:00 | gunicorn/run | Dynamic Python package installation is disabled.\n",
            "2022-09-27T20:15:30,356776014+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:30,361229524+00:00 | gunicorn/run | ###############################################\n",
            "2022-09-27T20:15:30,364340531+00:00 | gunicorn/run | AzureML Inference Server\n",
            "2022-09-27T20:15:30,371084246+00:00 | gunicorn/run | ###############################################\n",
            "2022-09-27T20:15:30,372759750+00:00 | gunicorn/run | \n",
            "2022-09-27T20:15:30,375252455+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n",
            "\n",
            "Azure ML Inferencing HTTP server v0.6.1\n",
            "\n",
            "\n",
            "Server Settings\n",
            "---------------\n",
            "Entry Script Name: main.py\n",
            "Model Directory: /var/azureml-app/azureml-models/diabetes_model_lala/1\n",
            "Worker Count: 1\n",
            "Worker Timeout (seconds): 300\n",
            "Server Port: 31311\n",
            "Application Insights Enabled: false\n",
            "Application Insights Key: None\n",
            "Inferencing HTTP server version: azmlinfsrv/0.6.1\n",
            "\n",
            "\n",
            "Server Routes\n",
            "---------------\n",
            "Liveness Probe: GET   127.0.0.1:31311/\n",
            "Score:          POST  127.0.0.1:31311/score\n",
            "\n",
            "Starting gunicorn 20.1.0\n",
            "Listening at: http://0.0.0.0:31311 (169)\n",
            "Using worker: sync\n",
            "Booting worker with pid: 245\n",
            "Initializing logger\n",
            "2022-09-27 20:15:34,571 | root | INFO | Starting up app insights client\n",
            "logging socket was found. logging is available.\n",
            "logging socket was found. logging is available.\n",
            "2022-09-27 20:15:34,573 | root | INFO | Starting up request id generator\n",
            "2022-09-27 20:15:34,574 | root | INFO | Starting up app insight hooks\n",
            "2022-09-27 20:15:34,575 | root | INFO | Invoking user's init function\n",
            "00000000-0000-0000-0000-000000000000,['diabetes_model.pkl']\n",
            "2022-09-27 20:15:37,235 | root | ERROR | User's init function failed\n",
            "2022-09-27 20:15:37,243 | root | ERROR | Encountered Exception Traceback (most recent call last):\n",
            "  File \"/opt/miniconda/envs/amlenv/lib/python3.7/site-packages/azureml_inference_server_http/server/aml_blueprint.py\", line 257, in register\n",
            "    main.init()\n",
            "  File \"/var/azureml-app/main.py\", line 35, in init\n",
            "    driver_module.init()\n",
            "  File \"/var/azureml-app/diabetes_service/score_diabetes.py\", line 14, in init\n",
            "    model = joblib.load(model_path)\n",
            "  File \"/opt/miniconda/envs/amlenv/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 587, in load\n",
            "    obj = _unpickle(fobj, filename, mmap_mode)\n",
            "  File \"/opt/miniconda/envs/amlenv/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 506, in _unpickle\n",
            "    obj = unpickler.load()\n",
            "  File \"/opt/miniconda/envs/amlenv/lib/python3.7/pickle.py\", line 1088, in load\n",
            "    dispatch[key[0]](self)\n",
            "KeyError: 0\n",
            "\n",
            "2022-09-27 20:15:37,244 | root | INFO | Waiting for logs to be sent to Application Insights before exit.\n",
            "2022-09-27 20:15:37,244 | root | INFO | Waiting 30 seconds for upload.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(service.get_logs())\n",
        "\n",
        "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
        "#service.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take a look at your workspace in [Azure Machine Learning Studio](https://ml.azure.com) and view the **Endpoints** page, which shows the deployed services in your workspace.\n",
        "\n",
        "You can also retrieve the names of web services in your workspace by running the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for webservice_name in ws.webservices:\n",
        "    print(webservice_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use the web service\n",
        "\n",
        "With the service deployed, now you can consume it from a client application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
        "print ('Patient: {}'.format(x_new[0]))\n",
        "\n",
        "# Convert the array to a serializable list in a JSON document\n",
        "input_json = json.dumps({\"data\": x_new})\n",
        "\n",
        "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
        "predictions = service.run(input_data = input_json)\n",
        "\n",
        "# Get the predicted class - it'll be the first (and only) one.\n",
        "predicted_classes = json.loads(predictions)\n",
        "print(predicted_classes[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also send multiple patient observations to the service, and get back a prediction for each one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# This time our input is an array of two feature arrays\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
        "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
        "\n",
        "# Convert the array or arrays to a serializable list in a JSON document\n",
        "input_json = json.dumps({\"data\": x_new})\n",
        "\n",
        "# Call the web service, passing the input data\n",
        "predictions = service.run(input_data = input_json)\n",
        "\n",
        "# Get the predicted classes.\n",
        "predicted_classes = json.loads(predictions)\n",
        "   \n",
        "for i in range(len(x_new)):\n",
        "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code above uses the Azure Machine Learning SDK to connect to the containerized web service and use it to generate predictions from your diabetes classification model. In production, a model is likely to be consumed by business applications that do not use the Azure Machine Learning SDK, but simply make HTTP requests to the web service.\n",
        "\n",
        "Let's determine the URL to which these applications must submit their requests:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint = service.scoring_uri\n",
        "print(endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON format, and receive back the predicted class(es)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
        "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
        "\n",
        "# Convert the array to a serializable list in a JSON document\n",
        "input_json = json.dumps({\"data\": x_new})\n",
        "\n",
        "# Set the content type\n",
        "headers = { 'Content-Type':'application/json' }\n",
        "\n",
        "predictions = requests.post(endpoint, input_json, headers = headers)\n",
        "predicted_classes = json.loads(predictions.json())\n",
        "\n",
        "for i in range(len(x_new)):\n",
        "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You've deployed your web service as an Azure Container Instance (ACI) service that requires no authentication. This is fine for development and testing, but for production you should consider deploying to an Azure Kubernetes Service (AKS) cluster and enabling token-based authentication. This would require REST requests to include an **Authorization** header.\n",
        "\n",
        "## Delete the service\n",
        "\n",
        "When you no longer need your service, you should delete it to avoid incurring unecessary charges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.delete()\n",
        "print ('Service deleted.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For more information about publishing a model as a service, see the [documentation](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('DP100-IdpZmbhO')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6be20d35a0fe9891e9592b51856519ffefec3add89e5783bfb8eccfc4b79debb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
